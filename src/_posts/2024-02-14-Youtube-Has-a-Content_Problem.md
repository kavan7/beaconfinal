
*YouTube* Has a Content Problem 

**Alisha Wong**

*Gr 12 CONTRIBUTOR*

*YouTube*'s attempts at content moderation have failed everyone. I’m sure everyone has heard terms like “alt right pipeline” and “rabbit hole” but what does *YouTube* really have to do with them? My answer is incompetent regulation, sinister negligence, and failure to improve flawed systems.

This year, *YouTube* focused on limiting the monetization of videos based on whether they used expletives in the first 8 to 15 seconds and demonetizing videos with specific words (there is a list online if you want to check it out) including “controversial” words like “blonde” or “aunty”. These new regulations hurt people who need *YouTube* as an income base. LGBTQ+ creators have been disproportionately impacted, as words included in this list such as “romantic” or “lesbians”, are commonly used in their videos.

It's unfair to say *YouTube* isn’t making efforts to curb harmful content. They have been making changes to their platform’s moderation policies, although it usually takes a lot of people online being very loud for *YouTube* to actually take their concerns seriously. In 2020, *YouTube* attempted to solve the problem of the “alt right pipeline” by removing a large amount of extremist content and preventing their algorithm from recommending it.

In April this year they stated their commitment to stopping their algorithm from recommending eating disorder videos to teenagers. And to that I say, “Thank you *YouTube* for doing the bare minimum!” Initially, I was skeptical that *YouTube* could even do this. There is a lot of content that promotes restrictive diets and “unhealthy behaviors” that does not appear to use words or images that seem dangerous. For instance, there is a growing movement on *YouTube* that promotes “Fruitarianism” which is a diet that only consists of eating fruit. Influencers who follow this diet claim that it stops body odor and can cure diseases like cancer. *YouTube* also has difficulty restricting television or film content related to eating disorders no matter how controversial, however, they appear to have no problem at all censoring the work of less influential creators who critique dangerous depictions of disordered eating.

` `Now the solution to *YouTube*’s content issue might seem clear: there should be more human moderators actively overseeing the platform. However, according to a 2019 lawsuit between a former *YouTube* moderator whose job was to watch 300 videos a day—many of which contained graphic, violent or otherwise traumatizing content— her office was “chronically understaffed” and she was not provided with any mental health support.

`	`There isn’t a clear cut answer to *YouTube*’s moderation problems. AI, as it turns out, is too restrictive and can discriminate against marginalized groups.  And, exposing human moderators to the horrors of the internet 8 hours a day seems like a CIA torture device, not a job.  

Clearly, *Youtube*'s current approach is not working. While they acknowledge their problems, saying there is a hole in the boat isn’t the same as fixing the leak. *YouTube* needs to listen to people’s concerns now and take the necessary steps to solve  them because a leaky boat can only be bailed out for so long. 


